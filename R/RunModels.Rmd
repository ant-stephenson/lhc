---
title: "Feature selection"
author: "Anthony Stephenson"
date: "1/3/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages
```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(Matrix)
library(fs)

source("utility_funcs.r")
source("plot_funcs.r")
source("model_funcs.r")
```

Load the data
```{r load data}
# divide data into training kaggle set, and retain hold-out (before further cross-validation partitioning)
source_path <- path_join(c(path_dir(path_dir(getwd()))))
filename <- "atlas-higgs-challenge-2014-v2.csv"
filepath <- path_join(c(source_path, "LHC_dump", "R", filename))
data <- import_data(filepath)
```

Kaggle sets:  ”t”:training, ”b”:public leaderboard, ”v”:private leaderboard, ”u”:unused.
```{r training set}
train_idx <- get_subset_idx(data$kaggle_s, c("t"))
X <- data$X[train_idx, ]
y <- data$y[train_idx]
# need to use kaggle weignts to make AMS correct?!
kaggle_w <- data$kaggle_w[train_idx]
w <- data$kaggle_w[train_idx]
nj <- data$nj[train_idx]
e_id <- data$e_id[train_idx]
```

```{r validation set}
# public leaderboard set
val_idx <- get_subset_idx(data$kaggle_s, c("b"))
Xv <- data$X[val_idx, ]
yv<- data$y[val_idx]
wv <- data$kaggle_w[val_idx]
njv <- data$nj[val_idx]
```

Apply some feature engineering
```{r add features}
# modify features
X <- reduce_features(X)
X <- invert_angle_sign(X)
Xv <- reduce_features(Xv)
Xv <- invert_angle_sign(Xv)
```

Initialise parameters
```{r init params}
n_rbf <- 5
s <- avg_median_pairwise_distance(X)

# Regularisation (L2) parameter [global]
lambda <- 100

# K-Fold CV partitioning
K <- 10
kI <- partition_data(length(y), K, random = TRUE)

n <- nrow(X)
d <- ncol(X) + n_rbf

ams <- rep(NA, length=6*K)
auc <- rep(NA, length=6*K)

sum_w <- sum(w)
```


Use missing data pattern to partition data
```{r jet/missing}
# get missing rows. separate by number of jets and presence of Higgs mass and fit separate models
# find columns with features with any missing values for each number of jets: 0, 1, 2+ in combination with the presence (or absence) of the Higgs mass, defined by j=1,2,3, 4, 5, 6. i.e. j=1 => nj=0 & mH != -999, j=2 => 
jet_cats <- c(1:3, 1:3)
idx_jet_cat <- function(nj, j) {
    if (j == 1) {
        nj == 0
    } else if (j == 2) {
        nj == 1
    } else if (j == 3) {
        nj >= 2
    } else {stop("Incorrect jet category specified")}
}
idx_higgs_mass <- function(X, j) {
    # for j>3 take rows with Higgs missing (and drop Higgs)
    is_missing <- is.na(X$"DER_mass_MMC")
    if (j > 3) {
        return(!is_missing)
    } else {return(is_missing)}
    
}
features_to_rm <- list(list(), list(), list())
for (mj in 1:6) {
    j <- jet_cats[mj]
    features_to_rm[[mj]] <- colnames(X)[colSums(is.na(X[idx_jet_cat(nj, j) & idx_higgs_mass(X, mj),])) > 0]
}
```

```{r test, include=FALSE}
midx <- matrix(, nrow=6*K,ncol=2)
  for (j in 1:6) {
    for (k in 1:K) {
      idx <- get_model_idx(j, k, K)
      midx[idx,] <- inv_model_idx(idx, K)
    }
  }
midx
```

Count the number of rows of data in each category and fold, with the first column being the training set and the second being the test for each fold/category
```{r number of rows}
n_rows_p_partition <- matrix(, nrow=6*K, ncol=2)
for (mj in 1:6) {
    # loop over sets of jet number {0, 1, 2+} and mH presence/absence
    for (k in 1:K) {
        j <- jet_cats[mj]
        fit_row_idx <- kI != k & idx_jet_cat(nj, j) & idx_higgs_mass(X, mj)
        test_row_idx <- kI == k & idx_jet_cat(nj, j) & idx_higgs_mass(X, mj)

        model_idx <- get_model_idx(mj, k, K)

        n_rows_p_partition[model_idx, 1] <- sum(fit_row_idx)
        n_rows_p_partition[model_idx, 2] <- sum(test_row_idx)
    }
}
n_rows_p_partition
```

Run models
```{r fitting}
# loop over folds
#create lists to hold the k models and k roc curves
models <- vector("list", 6*K)
rocs <- vector("list", 6*K)
b <- matrix(, nrow=d, ncol=6 * K)

par(mfrow=c(2, 3))
for (mj in 1:6) {
    # loop over sets of jet number {0, 1, 2+} and mH presence/absence
    for (k in 1:K) {
        j <- jet_cats[mj]
        fit_row_idx <- kI != k & idx_jet_cat(nj, j) & idx_higgs_mass(X, mj)
        test_row_idx <- kI == k & idx_jet_cat(nj, j) & idx_higgs_mass(X, mj)

        # add r RBF centroid features, using the same reference centroids in training and testing sets
        if (n_rbf > 0) {
          rbf_centroids <- get_rbf_centroids(X[fit_row_idx, ], n_rbf)
          Xi <- rbf_centroids$"xi"
          Xtrain <- add_rbf_features(X[fit_row_idx, ], s, n_rbf, Xi=Xi)
          Xtest <- add_rbf_features(X[test_row_idx, ], s, n_rbf, Xi=Xi)
        } else {
          Xtrain <- X[fit_row_idx, ]
          Xtest <- X[test_row_idx, ]
        }
        
        col_idx <- get_valid_cols(colnames(X), features_to_rm, mj)

        Xtrain <- as.matrix(Xtrain[, col_idx])
        Xtest <- as.matrix(Xtest[, col_idx])

        model_idx <- get_model_idx(mj, k, K)

        #fit a logistic regression model to the CV training data
        models[[model_idx]] <- logistic_model$new(X=Xtrain, y=y[fit_row_idx], lambda=lambda)
        b[col_idx, model_idx] <- models[[model_idx]]$coeffs
  
        #use it to predict the classifications of the test data
        p_hat <- models[[model_idx]]$predict(Xtest)

        #create an ROC curve object
        rocs[[model_idx]] <- ROC_curve$new(y[test_row_idx], p_hat)
        
        # probably want to tune the threshold? why does (very) low threshold give better ams?
        y_hat <- decide(p_hat, thresh = 0.4)

        ams[model_idx] <- calculate_ams_partition(y[test_row_idx], y_hat, w[test_row_idx], sum_w=sum_w)
    }
}
```
```{r avg auc and plot roc, error=TRUE}
auc <- sapply(rocs, function(x) x$calc_auc())
for(j in 1:6){
  #find average auc over folds
  i1 <- get_model_idx(j, 1, K)
  i2 <- get_model_idx(j, K, K)
  average_auc <- mean(sapply(rocs[i1:i2], function(x) x$auc), na.rm=TRUE)
  #get a plot of the k ROC curves on the same axis
  rocs[[1]]$plot_curve(title=sprintf("All training data, %i-fold CV, Average AUC %.3f", K, round(average_auc, 3)))
  for (k in 1:K) {
    rocs[[get_model_idx(j, k, K)]]$plot_curve(add=T)
  }
}

```

Fit model (for each category) on whole (unfolded) dataset
```{r full model}
# loop over folds
#create lists to hold the k models and k roc curves
full_models <- vector("list", 6)
full_rocs <- vector("list", 6)
full_ams_IS <- rep(NA, length=6)
rbf_idx <- matrix(, nrow=6, ncol=n_rbf)
# check warnings?
for (mj in 1:6) {
    # loop over sets of jet number {0, 1, 2+} and mH presence/absence
    j <- jet_cats[mj]
    fit_row_idx <- idx_jet_cat(nj, j) & idx_higgs_mass(X, mj)
    test_row_idx <- idx_jet_cat(nj, j) & idx_higgs_mass(X, mj)
        
    if (n_rbf > 0) {
      # add r RBF centroid features, using the same reference centroids in training and testing sets
      rbf_centroids <- get_rbf_centroids(X[fit_row_idx, ], n_rbf)
      Xi <- rbf_centroids$"xi"
      # record which rows to use for OOS in public set (or any other OOS)
      rbf_idx[mj, ] <- rbf_centroids$"idx"
      Xtrain <- add_rbf_features(X[fit_row_idx, ], s, n_rbf, Xi=Xi)
      Xtest <- add_rbf_features(X[test_row_idx, ], s, n_rbf, Xi=Xi)
    } else {
          Xtrain <- X[fit_row_idx, ]
          Xtest <- X[test_row_idx, ]
    }

    col_idx <- get_valid_cols(colnames(Xtrain), features_to_rm, mj)

    Xtrain <- as.matrix(Xtrain[, col_idx])
    Xtest <- as.matrix(Xtest[, col_idx])

    model_idx <- get_model_idx(mj, 1, 1)

    #fit a logistic regression model to the CV training data
    full_models[[model_idx]] <- logistic_model$new(X=Xtrain, y=y[fit_row_idx], lambda=lambda)
  
    #use it to predict the classifications of the test data
    p_hat <- full_models[[model_idx]]$predict(Xtest)

    #create an ROC curve object
    full_rocs[[model_idx]] <- ROC_curve$new(y[test_row_idx], p_hat)
        
    # probably want to tune the threshold? why does (very) low threshold give better ams?
    y_hat <- decide(p_hat, thresh = 0.4)

    full_ams_IS[model_idx] <- calculate_ams_partition(y[test_row_idx], y_hat, w[test_row_idx], sum_w=sum_w)
}
```

Test on (until now unseen) validation set. Calling it validation as we can then use the summary metrics to tune free parameters.
```{r public}
amsv <- rep(NA, length=6)

# check warnings
sum_wv <- sum(wv)
for (mj in 1:6) {
    j <- jet_cats[mj]
    test_row_idx <- idx_jet_cat(njv, j) & idx_higgs_mass(Xv, mj)

    if (n_rbf > 0) {
      # add r RBF centroid features, using the same reference centroids in training and testing sets
      Xi <- X[rbf_idx[mj, ], ]
      Xtest <- add_rbf_features(Xv[test_row_idx, ], s, n_rbf, Xi=Xi)
    } else {
          Xtest <- Xv[test_row_idx, ]
    }
    
    col_idx <- get_valid_cols(colnames(Xtest), features_to_rm, mj)

    Xtest <- as.matrix(Xtest[, col_idx])

    model_idx <- get_model_idx(mj, 1, 1)

    #use it to predict the classifications of the test data
    p_hat <- full_models[[model_idx]]$predict(Xtest)

    #create an ROC curve object
    full_rocs[[model_idx]] <- ROC_curve$new(yv[test_row_idx], p_hat)
    # probably want to tune the threshold? why does (very) low threshold give better ams?
    y_hat <- decide(p_hat, thresh = 0.4)

    amsv[model_idx] <- calculate_ams_partition(yv[test_row_idx], y_hat, wv[test_row_idx], sum_w=sum_wv)
}
```

```{r plot public}
for(j in 1:6){
  #find average auc over folds
  full_rocs[[j]]$calc_auc()
  #get a plot of the k ROC curves on the same axis
  full_rocs[[get_model_idx(j, 1, 1)]]$plot_curve(title=sprintf("All training data, public test-set, OOS AUC %.3f, group %i", round(full_rocs[[j]]$auc, 3), j))
}
aucv <- sapply(full_rocs, function(x) x$auc)
```
Summary results:
```{r print}
sprintf("CV OOS AUC = %.2f ± %.1f", mean(auc), mad(auc))
sprintf("CV OOS AMS = %.2f ± %.1f", mean(ams), mad(ams))
sprintf("Validation set AUC = %.2f ± %.1f", mean(aucv), mad(aucv))
sprintf("Validation set AMS = %.2f ± %.1f", mean(amsv), mad(amsv))
```
