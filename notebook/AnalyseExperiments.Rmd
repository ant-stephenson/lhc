---
title: "Analyse Experiments"
author: "Anthony Stephenson"
date: "1/18/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r import}
library(ggplot2)
library(dplyr)
library(fs)
library(lhc)
```

# Analyse Experiments

```{r import}
filepath <- path_join(c(dirname(getwd()), "/output/results_experiments4.csv"))
exp_data <- read.csv(filepath)
```

Remove some columns that are not important for this analysis and average over any duplicated experiments:
```{r extract summarise}
exp_data <- exp_data[, !colnames(exp_data) %in% c("c", "Train", "Validation", "model_type")]
exp_data <- exp_data %>% group_by(n_rbf, lambda, poly) %>% summarise_all(funs(mean)) %>% as.data.frame()
```

Implement a convenient plotting function to summarise results.
```{r plot}
# define function to plot against our metric
plot_metric <- function(data, xlabel, ylabel, loop_label=NULL, filt0=TRUE, ...) {
  if (!is.null(loop_label)) {
    init_idx <- min(data[, loop_label])
    ntrials <- max(data[, loop_label])-(-1 + init_idx)
    filt_func <- function(x) data[, loop_label] == x & filt0
  } else{
    ntrials <- 1
    init_idx <- 0
    filt_func <- function(x) filt0
  }
  
  colours <- generate_colours(ntrials)
  
  ylim <- c(min(data[filt0, ylabel]), max(data[filt0, ylabel]))
  
  filt <- filt_func(init_idx)
  plot(data[filt, xlabel], data[filt, ylabel], col=colours[1], type="lin", xlab=xlabel, ylab=ylabel, main=sprintf("%s vs %s for different %s", ylabel, xlabel, loop_label), ylim=ylim, ...)
  for (i in 1:ntrials) {
    nr <- i + init_idx
    filt <- filt_func(nr)
    lines(data[filt, xlabel], data[filt, ylabel], col=colours[nr])
  }
  legend("bottomleft", legend=c(init_idx:(ntrials+(init_idx-1))), fill=colours)
}
```

Run plots for various permutations of our model parameters to see their relative performance on our key metrics:
```{r run the plots}
# order by our x variable
exp_data <- exp_data[order(exp_data[, "lambda"]), ]

# plot AUC and AMS vs regularisation parameter lambda for different numbers of RBF centroids, for no polynomial transformations added
filt0 <- exp_data[, "poly"]==1
plot_metric(exp_data, "lambda", "auc", "n_rbf", filt0, log="x")
plot_metric(exp_data, "lambda", "ams", "n_rbf", filt0, log="x")

# plot AUC and AMS vs regularisation parameter lambda for different numbers of RBF centroids, for second order polynomial transformations added
filt0 <- exp_data[, "poly"]==2
plot_metric(exp_data, "lambda", "auc", "n_rbf", filt0, log="x")
plot_metric(exp_data, "lambda", "ams", "n_rbf", filt0, log="x")

# plot AUC and AMS vs regularisation parameter lambda for different numbers of RBF centroids, for 2nd and 3rd order polynomial transformations added
filt0 <- exp_data[, "poly"]==3
plot_metric(exp_data, "lambda", "auc", "n_rbf", filt0, log="x")
plot_metric(exp_data, "lambda", "ams", "n_rbf", filt0, log="x")

# plot AUC and AMS vs regularisation parameter lambda for different numbers of orders of polynomial transformations, for no added RBF centroids
filt0 <- exp_data[, "n_rbf"]==0
plot_metric(exp_data, "lambda", "auc", "poly", filt0, log="x")
plot_metric(exp_data, "lambda", "ams", "poly", filt0, log="x")

# plot AUC and AMS (scaled by respective mean absolute deviation) vs regularisation parameter lambda for different numbers of orders of polynomial transformations, for no added RBF centroids
filt0 <- exp_data[, "n_rbf"]==0
plot_metric(exp_data, "lambda", "scaled.auc", "poly", filt0, log="x")
plot_metric(exp_data, "lambda", "scaled.ams", "poly", filt0, log="x")

# plot boxplots of scaled AUC and AMS for each polynomial transformation
boxplot(scaled.auc~poly, data=exp_data, main="Scaled AUC for each order polynomial transformation")
boxplot(scaled.ams~poly, data=exp_data, main="Scaled AMS for each order polynomial transformation")

# plot boxplots of scaled AUC and AMS for additional RBF centroid
boxplot(scaled.auc~n_rbf, data=exp_data, main="AUC for each additional RBF centroid")
boxplot(scaled.ams~n_rbf, data=exp_data, main="AMS for each additional centroid feature")
```

Print results as a LaTeX table that can be imported into a report easily. Not too surprisingly we see different models appear at the top of our list depending on how we decide to choose the best model. Since our goal is ultimately to maximise AMS, it makes sense that this (rather than AUC) should be the metric we choose, despite the higher variance it displays. To try and mitigate this variance, we can  choose to sort by a scaled version of AMS, where we take the mean absolute deviation across the folds and scale by that, to try and optimise for the best result with the least variation and therefore hopefully the best generalisation.

Surprisingly, the top model appears to have the following set of parameters: $n_{rbf}=2$, $\lambda = 1e-4$ and the inclusion of upto 3rd order polynomial terms.
```{r latex output}
library(Hmisc)
# consider scaling metrics by MAD(metric) to get a handle on variation
scaled_auc <- exp_data[,"auc"]/exp_data[,"mad.auc."]
scaled_ams <- exp_data[,"ams"]/exp_data[,"mad.ams."]
exp_data[, "scaled.auc"] <- scaled_auc
exp_data[, "scaled.ams"] <- scaled_ams
#scaled <- head(arrange(exp_data, scaled_ams, scaled_auc))

# sort/filter data to only retain what we want to record and round numerical values to 3d.p for readibility
output <- exp_data[, c("n_rbf", "lambda", "poly", "auc", "mad.auc.", "ams", "mad.ams.", "scaled.auc", "scaled.ams")] %>%
  arrange(desc(scaled.ams), desc(scaled.auc)) %>%
  mutate_if(is.numeric, round, digits=3)

# keep top 5 rows
output <- output[1:5, ]
print(output)

# make column names latex friendly
colnames(output) <- sub("(\\w+)\\.(\\w+)\\.?", "\\$\\1_\\{\\2\\}\\$", colnames(output))
colnames(output) <- sub("n\\_rbf", "\\$n_{rbf}\\$", colnames(output))

# Generate LaTeX table
latex(output, file=path_join(c(dirname(getwd()), "doc/results_table.tex")), caption="Results table of the top 5 experiments")
```
